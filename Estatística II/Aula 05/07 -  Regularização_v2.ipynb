{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Regularizações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa aula, iremos tratar dos seguintes conteúdos:\n",
    "- Função de Custo e Regularização;\n",
    "- Ridge;\n",
    "- Lasso;\n",
    "- Elastic-Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regularizações\n",
    "\n",
    "<br>\n",
    "\n",
    "As __regularizações__ vão ser uma importante ferramenta para auxiliar no ajuste de modelos de Regressão Linear. Quando modela-se uma Regressão Linear Múltipla, o objetivo é calcular os coeficientes que determinam a equação abaixo:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\ Y_j=\\beta_0 + \\sum_{i=1}^{n} \\beta_i X_{ij} = \\beta_0 + \\beta X $$\n",
    "\n",
    "<br>\n",
    "\n",
    "Para se determinar os valores de todos os parâmetros $\\beta$, o processo de modelagem envolve achar os parâmetros que minimizam a chamada __função de custo__, função esta que avalia o custo (ou seja o erro empregado) ao estimar o valor de $Y$, que para o caso das regressões a função de custo é dada pela __soma residual dos quadrados__, conforme a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\Theta = \\sum_{i = 1}^{n}[y_i - (\\beta_0 + \\beta X)]^2\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Mas durante o processo iterativo para o cálculo dos parâmetros, um problema que pode surgir é o caso do _overfitting_, como discutido em tópicos anterior. Ao invés do modelo aprender a __generalizar os resultados__, ele apenas passa a __memorizar__ as respostas dos dados fornecidos no treinamento, prejudicando assim o real poder de predição da Regressão Linear e qualquer outro modelo de _Machine Learning_.\n",
    "\n",
    "A forma utilizada para diminuir esse efeito nas regressões, seria justamente a __regularização__, onde de acordo com o tipo de regularização será adicionado a função de custo um termo conhecido como __penalização__ proporporcional aos coeficientes $\\beta$. Dessa forma, ao minimizar a função de custo, também será minimizado os parâmetros $\\beta$.\n",
    "\n",
    "Nos tópicos a seguir, serão apresentados os principais métodos de regularização para as regressões, sendo eles o __Ridge__, __Lasso__ e __Elastic-Net__.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "###  Ridge (L2)\n",
    "\n",
    "<br>\n",
    "\n",
    "O método Ridge ou penalização L2, consiste em adicionar um termo quadrático dos parâmetros na função de custo:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\Theta_{Ridge} = \\sum_{i = 1}^{n}[y_i - (\\beta_0 + \\beta X)]^2 + \\alpha\\sum_{j = 1}^{p}\\beta^{2}_{j} \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Esse tipo de regularização é mais interessante de se usar quando __todas as variáveis atributos dos dados são importantes__, mas esperasse que o modelo generalize mais. O parâmetro $\\alpha$ é justamente o que define a complexidade do modelo, quanto maior o $\\alpha$, mais simples o modelo, ou seja, menor a viriância e maiores chances de ocorrer um _underfitting_.\n",
    "\n",
    "O processo de treinamento e geração de novas predições funciona de forma análoga ao que acontece para a função `LinearRegression`, no caso para implementar o [_Ridge_](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) basta carregar a função específica para ele:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carregando a função para o Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = Ridge(alpha = 1.0) # Parâmetro de Ajuste do Ridge\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "###  Lasso (L1)\n",
    "\n",
    "<br>\n",
    "\n",
    "O método Lasso ou penalização L1, consiste em adicionar o módulo dos parâmetros na função de custo, ao invés do quadrado no Ridge:\n",
    "\n",
    "$$\n",
    "\\Theta_{Lasso} = \\sum_{i = 1}^{n}[y_i - (\\beta_0 + \\beta X)]^2 + \\alpha\\sum_{j = 1}^{p}|\\beta_{j}|\n",
    "$$\n",
    "\n",
    "O Lasso tem uma aplicação adicional bem interessante pois, no processo interativo de minimizar a função de custo, alguns parâmetros $\\beta$ serão __zerados__. Ou seja, o método pode ser utilizado como __uma seleção de atributos__, onde serão zerados os atributos menos relevantes para a modelagem. No caso do Lasso, se tivermos $\\alpha = 0$ cai-se no caso clássico de regressão linear e para os casos $\\alpha > 0$, quanto maior o valor de lambda, mais parâmetros serão zerados. \n",
    "\n",
    "De forma análoga ao que acontece no _Ridge_, no caso para implementar o [__Lasso__](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html?highlight=lasso#sklearn.linear_model.Lasso) basta carregar a função específica para ele:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carregando a função para o Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = Ridge(alpha = 1.0) # Parâmetro de Ajuste do Lasso\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "###  Elastic-Net (L1 + L2)\n",
    "\n",
    "<br>\n",
    "\n",
    "O __Elastic-Net__ é um caso particular bem interessante pois ele combina ambos os efeitos de penalização L1 e L2, conforme descrito pela fórmula a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\Theta_{EN} = \\sum_{i = 1}^{n}[y_i - (\\beta_0 + \\beta X)]^2 + \\alpha_{1}\\sum_{j = 1}^{p}|\\beta_{j}| + \\alpha_{2}\\sum_{j = 1}^{p}\\beta_{j}^{2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Ou seja, o _Elastic-Net_ é interessante pois combina o poder de penalização efetiva do _Ridge_ com as características de seleção de atributos do _Lasso_. Para implementar o [_Elastic-Net_](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) basta carregar a sua função específica:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carregando a função para o ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = ElasticNet(alpha = 1.0) # Parâmetro de Ajuste do ElasticNet\n",
    "```\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exemplo:__ Vamos retomar o exercício com o _dataset_ `Car_Prices.csv` e avaliar os dados com diferentes modelos agora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das Libs necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando o CSV\n",
    "cars = pd.read_csv('Car_Prices.csv', index_col=0)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatísticas interessantes sobre o dataset\n",
    "cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o get_dummies\n",
    "cars_with_dummies = pd.get_dummies(cars, \n",
    "                                   prefix_sep='_', \n",
    "                                   columns=['fueltype', \n",
    "                                            'aspiration', \n",
    "                                            'doornumber', \n",
    "                                            'carbody', \n",
    "                                            'cylindernumber'],\n",
    "                                   drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Olhando a transformação\n",
    "cars_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em X e Y\n",
    "X = cars_with_dummies.drop(['CarName', 'price'], axis = 1)\n",
    "y = cars_with_dummies['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia a normalização\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a normalização nos dados de treino\n",
    "X_train_std = std.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a normalização nos dados de teste\n",
    "X_test_std = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dos dados (ou seja, vamos passar os dados para o modelo aprender com eles)\n",
    "linreg.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os dados novos, vamos definir a predição para a base de teste\n",
    "y_pred = linreg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Importance - LinReg\n",
    "coefs = linreg.coef_\n",
    "\n",
    "list_columns = X_train.columns\n",
    "list_feature = []\n",
    "list_score = []\n",
    "\n",
    "for i, v in enumerate(coefs):\n",
    "    list_feature.append(list_columns[i])\n",
    "    list_score.append(v)\n",
    "\n",
    "dictionary = {'Features': list_feature,\n",
    "              'Scores': list_score}\n",
    "\n",
    "df_features = pd.DataFrame(dictionary)\n",
    "df_features = df_features.sort_values(by=['Scores'], ascending=False)\n",
    "df_features.reset_index(inplace=True, drop=True)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dos dados (ou seja, vamos passar os dados para o modelo aprender com eles)\n",
    "ridge.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os dados novos, vamos definir a predição para a base de teste\n",
    "y_pred_ridge = ridge.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Ridge\n",
    "coefs2 = ridge.coef_\n",
    "\n",
    "list_columns = X_train.columns\n",
    "list_feature = []\n",
    "list_score = []\n",
    "\n",
    "for i, v in enumerate(coefs2):\n",
    "    list_feature.append(list_columns[i])\n",
    "    list_score.append(v)\n",
    "\n",
    "dictionary = {'Features': list_feature,\n",
    "              'Scores': list_score}\n",
    "\n",
    "df_features2 = pd.DataFrame(dictionary)\n",
    "df_features2 = df_features2.sort_values(by=['Scores'], ascending=False)\n",
    "df_features2.reset_index(inplace=True, drop=True)\n",
    "df_features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "lasso = Lasso(max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dos dados (ou seja, vamos passar os dados para o modelo aprender com eles)\n",
    "lasso.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os dados novos, vamos definir a predição para a base de teste\n",
    "y_pred_lasso = lasso.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Lasso\n",
    "coefs3 = lasso.coef_\n",
    "\n",
    "list_columns = X_train.columns\n",
    "list_feature = []\n",
    "list_score = []\n",
    "\n",
    "for i, v in enumerate(coefs3):\n",
    "    list_feature.append(list_columns[i])\n",
    "    list_score.append(v)\n",
    "\n",
    "dictionary = {'Features': list_feature,\n",
    "              'Scores': list_score}\n",
    "\n",
    "df_features3 = pd.DataFrame(dictionary)\n",
    "df_features3 = df_features3.sort_values(by=['Scores'], ascending=False)\n",
    "df_features3.reset_index(inplace=True, drop=True)\n",
    "df_features3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo\n",
    "EN = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dos dados (ou seja, vamos passar os dados para o modelo aprender com eles)\n",
    "EN.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para os dados novos, vamos definir a predição para a base de teste\n",
    "y_pred_EN = EN.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Elastic-Net\n",
    "coefs4 = EN.coef_\n",
    "\n",
    "list_columns = X_train.columns\n",
    "list_feature = []\n",
    "list_score = []\n",
    "\n",
    "for i, v in enumerate(coefs4):\n",
    "    list_feature.append(list_columns[i])\n",
    "    list_score.append(v)\n",
    "\n",
    "dictionary = {'Features': list_feature,\n",
    "              'Scores': list_score}\n",
    "\n",
    "df_features4 = pd.DataFrame(dictionary)\n",
    "df_features4 = df_features2.sort_values(by=['Scores'], ascending=False)\n",
    "df_features4.reset_index(inplace=True, drop=True)\n",
    "df_features4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando as métricas para avaliar os modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resultados para R2 Score:')\n",
    "print('R2 - Regressão Linear: ', np.round(r2_score(y_test, y_pred), 4))\n",
    "print('R2 - Ridge:            ', np.round(r2_score(y_test, y_pred_ridge), 4))\n",
    "print('R2 - Lasso:            ', np.round(r2_score(y_test, y_pred_lasso), 4))\n",
    "print('R2 - Elastic-Net:      ', np.round(r2_score(y_test, y_pred_EN), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resultados para MSE:')\n",
    "print('MSE - Regressão Linear: ', np.round(mean_squared_error(y_test, y_pred), 4))\n",
    "print('MSE - Ridge:            ', np.round(mean_squared_error(y_test, y_pred_ridge), 4))\n",
    "print('MSE - Lasso:            ', np.round(mean_squared_error(y_test, y_pred_lasso), 4))\n",
    "print('MSE - Elastic-Net:      ', np.round(mean_squared_error(y_test, y_pred_EN), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resultados para MAE:')\n",
    "print('MAE - Regressão Linear: ', np.round(mean_absolute_error(y_test, y_pred), 4))\n",
    "print('MAE - Ridge:            ', np.round(mean_absolute_error(y_test, y_pred_ridge), 4))\n",
    "print('MAE - Lasso:            ', np.round(mean_absolute_error(y_test, y_pred_lasso), 4))\n",
    "print('MAE - Elastic-Net:      ', np.round(mean_absolute_error(y_test, y_pred_EN), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Reavaliar o conjunto de dados para `Insurance.csv` e fazer o comparativo entre os modelos de regularização com a Regressão Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ Reavaliar o conjunto de dados para `Admission_Predict.csv` e fazer o comparativo entre os modelos de regularização com a Regressão Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3)__ Reavaliar o conjunto de dados para `usa_housing.csv` e fazer o comparativo entre os modelos de regularização com a Regressão Linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4)__ Utilizando o dataset `penguins` e a partir dos modelos de Regressão e regularização, desenvolva uma regressão para determinar o valor da massa corporal dos pinguins (`body_mass_g`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
