{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Redução de Dimensionalidade e Dados Categóricos\n",
    "\n",
    "Nessa aula, iremos tratar dos seguintes conteúdos:\n",
    "- Redução de Dimensionalidade;\n",
    "- PCA;\n",
    "- Dados Categóricos;\n",
    "- Teste Qui-Quadrado;\n",
    "- Teste ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Redução de Dimensionalidade\n",
    "\n",
    "## 1.1 Introdução\n",
    "\n",
    "<br>\n",
    "\n",
    "Com o avanço tecnológico e com aumento gradativo da geração e armazenamento de dados, os conjuntos de dados a serem trabalhados por modelos de _Machine Learning_ e _Data Science_ estão cada vez maiores e mais complexos, implicando também em um aumento gradativo do poder e tempo de processamento de máquinas sejam elas locais ou em processamento em nuvem.\n",
    "\n",
    "Mas com o objetivo de minimizar estes impactos, existem algumas técnicas complementares visando auxiliar e diminuir esta carga de processamento, uma dessas técnicas seria a __redução de dimensionalidade__. Redução de dimensionalidade é uma técnica bastante usada em conjunto de dados, normalmente grandes, com o objetivo de aumentar a interpretabilidade dos dados minimizando a quantidade de informação perdida no processo.\n",
    "\n",
    "uma das principais técnicas de redução de dimensionalidade utilizadas é o __Análise de Componente Principal (PCA)__, técnicas que será detalhada a seguir.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 1.2 Análise de Componente Principal (PCA)\n",
    "\n",
    "<br>\n",
    "\n",
    "A Análise de Componente Principal (_Principal Component Analysis_ em inglês) é a técnica para reduzir a dimensionalidade desses conjuntos de dados, aumentando a interpretabilidade concomitante a minimização da perda de informações. Isso é feito criando novas variáveis não correlacionadas, preservando o máximo de variabilidade possível. O processo matemático por trás disso consiste em uma transformação linear buscando calcular os __autovetores__ e indicando as direções principais deste conjunto de dados.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/03/2-1-e1458494877196.png\" width=800>\n",
    "\n",
    "Fonte: [Analytic Vidhya](https://www.analyticsvidhya.com/wp-content/uploads/2016/03/2-1-e1458494877196.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Este processo basicamente reduz a dimensionalidade do conjunto de dados em um valor $n$, onde $n$ é a quantidade de dimensões a serem utilizadas, retornando pelo PCA uma quantidade $n$ de componentes principais que representam a variabilidade dos dados.\n",
    "\n",
    "Algumas das vantagens desse processo seria o ganho de uma **interpretação gráfica dos dados** minimizando a perda de informação e também um processo interessante para utilizar em testes de modelo onde seria necessa´rio utilizar um __conjunto de dados muito grande__, pois testa-se o modelo com poucas variáveis mas sem perder o valor e a variabilidade dos dados originais.\n",
    "\n",
    "A implementação em _Python_ para o PCA é dada pelo bloco de código abaixo:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carregando o PCA do Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Istanciando o PCA\n",
    "pca = PCA(n_components = 2,  # Quantidade de componentes que serão utilizadas\n",
    "          random_state = 42) # Semente Aleatório\n",
    "\n",
    "# Transforma os dados e cria o número de componentes necessários\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "```\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dados Categóricos\n",
    "\n",
    "## 2.1 Introdução\n",
    "\n",
    "<br>\n",
    "\n",
    "Os dados categóricos são os tipos de variáveis definidos anteriormente como variáveis __qaulitativas__ e que poderiam ser separados em dois principais tipos, __nominais__ ou __ordinais__ como definidos abaixo:\n",
    "\n",
    "<br> \n",
    "\n",
    "- __qualitativa nominal__: as variáveis do tipo qualitativas não apresentam valores mensuráveis. No caso das variáveis __qualitativas__ e __nominais__, as variáveis __não apresentam uma ordenação ou hierárquia__ entre as categorias. __Exemplo:__ Sexo, País, estado civil e etc;\n",
    "\n",
    "- __qualitativa ordinal__: Já para as variáveis __qualitativas__ e __ordinais__, as variáveis __apresentam uma ordenação ou hierárquia__ entre as categorias. __Exemplo:__ escolaridade, faixa salarial, período do dia e etc.\n",
    "\n",
    "<br>\n",
    "\n",
    "De forma análoga ao processo feito com as variáveis __quantitativas__ (no caso númericas), existem testes de hipóteses que são capazes de dizer a qualidade de uma determinada variável categórica em relação ao poder de separação em um modelo. Os testes que são aplicados em variáveis categóricas são os chamados de __testes não-paramétricos__.\n",
    "\n",
    "Nos tópicos a seguir, será discutido a respeito de dois testes muito utilizados no processo de __seleção de atributos__, estes testes são o __Qui-Quadrado__ e __ANOVA__\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 2.2 Teste Qui-Quadrado\n",
    "\n",
    "<br>\n",
    "\n",
    "O Teste __Qui-Quadrado__ (_Chi-Squared_ em inglês) é um teste não-paramétrico que mede a relação de dependência entre duas variáveis categóricas, verificando se os valores esperados estão muito distantes dos valores observados para estas métricas. Ou seja, dados o vetor de contagens observadas $Oij=(O_{11},O_{12}, .…, O_{rc})$, r $E_{ij}$ representa os valores esperadas e admintindo válida a hipótese de independência dos critérios de classificação, a estatística para oteste de Qui-Quadrado pode ser definida a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ X^2 = \\sum_{i=1}^r \\sum_{j=1}^c \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Para valores altos da estatística do QUi_quadrado (respectivamente um valor baixo para o _p-value_), significa uma evidência forte que os valores observados e esperados são diferentes, portanto possuem dependência entre si. Esse grau de dependência entre as variáveis está relacionado diretamente com o valor do Qui_quadrado, quanto maior o valor da estatística, maior a dependência.\n",
    "\n",
    "A implementação em _Python_ para o teste Quidrado pode ser feito conforme o código a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carrega a função do Qui Quadrado\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Aplicando o teste Qui quadrado\n",
    "chi_scores = chi2(X, # Todas as variáveis categóricas\n",
    "                  y) # Variável resposta \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Dessa forma, é possível determinar dentre todas as variáveis categóricas em um conjunto de dados, quais que têm forte dependência com a variável resposta, em modelos de classificação no caso. Vale ressaltar que as variáveis categóricas devem ser convertidas para uma identificação númerica antes de aplicar o teste.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 2.3 ANOVA\n",
    "\n",
    "<br>\n",
    "\n",
    "O teste __ANOVA__ (_Analysis of Variance_ em inglês) é um teste não-paramétrico para verificar se existe diferenças significativas entre as médias de grupos de dados, sendo possível inferir se as variáveis são dependentes uma sobre a outra. Para isso, calcula-se a relação entre a variância entre grupos $S_B^2$ com a variância dentro dos grupos $S_W^2$, conforme a fórmula a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ F = \\frac{S_B^2}{S_W^2}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "A partir da estatística do valor $F$, quanto maior for a variância entre os grupos, mais diferentes as duas variáveis serão entre si. Dessa forma de acordo com o valor $F$ pode se inferir a respeito das variáveis serem diferentes e exercerem influência entre si.\n",
    "\n",
    "A implementação em _Python_ para o teste ANOVA pode ser feito conforme o código a seguir:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carrega a função ANOVA\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Aplicando o teste Qui quadrado\n",
    "F_scores = f_classif(X, # Todas as variáveis categóricas\n",
    "                     y) # Variável resposta \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "De forma análoga ao Qui-Quadrado, com este teste é possível determinar dentre todas as variáveis categóricas em um conjunto de dados, quais que têm forte dependência com a variável resposta, em modelos de classificação no caso. Vale ressaltar novamente que as variáveis categóricas devem ser convertidas para uma identificação númerica antes de aplicar o teste.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Qui-Quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Realize uma classificação com da coluna y dos dados de marketing bancário (contido no arquivo `bank-full.csv`) utilizando uma Regressão Logística. Após isso faça o processo de seleção de atributos utilizados o Lasso e Os testes Qui-Quadrado e ANOVA. Qual resultado do modelo ficou melhor antes ou depois da seleção de atributos? Plote os dados de teste utilizando o PCA e compare as separações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/bank-full.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ Vamos trabalhar com o dataset `sports.csv`, para predizer se um determinado atleta têm mais que 5 anos de carreira ou não (está é justamente a marcação de _target_ na base). Para o desenvolvimento do exercício aplique uma seleção de atributos, depois modele utilizando uma Regressão Logística e por fiz avalie a separação dos dados com o PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GamesPlayed</th>\n",
       "      <th>MinutesPlayed</th>\n",
       "      <th>PointsPerGame</th>\n",
       "      <th>FieldGoalsMade</th>\n",
       "      <th>FieldGoalsAttempt</th>\n",
       "      <th>FieldGoalPercent</th>\n",
       "      <th>3PointMade</th>\n",
       "      <th>3PointAttempt</th>\n",
       "      <th>3PointPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>FreeThrowAttempt</th>\n",
       "      <th>FreeThrowPercent</th>\n",
       "      <th>OffensiveRebounds</th>\n",
       "      <th>DefensiveRebounds</th>\n",
       "      <th>Rebounds</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Steals</th>\n",
       "      <th>Blocks</th>\n",
       "      <th>Turnovers</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Chris Smith</td>\n",
       "      <td>80</td>\n",
       "      <td>15.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>Brent Price</td>\n",
       "      <td>68</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Marlon Maxey</td>\n",
       "      <td>43</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>64.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>Litterial Green</td>\n",
       "      <td>52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>43.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>Jon Barry</td>\n",
       "      <td>47</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  GamesPlayed  MinutesPlayed  PointsPerGame  \\\n",
       "0      Brandon Ingram           36           27.4            7.4   \n",
       "1     Andrew Harrison           35           26.9            7.2   \n",
       "2      JaKarr Sampson           74           15.3            5.2   \n",
       "3         Malik Sealy           58           11.6            5.7   \n",
       "4         Matt Geiger           48           11.5            4.5   \n",
       "...               ...          ...            ...            ...   \n",
       "1335      Chris Smith           80           15.8            4.3   \n",
       "1336      Brent Price           68           12.6            3.9   \n",
       "1337     Marlon Maxey           43           12.1            5.4   \n",
       "1338  Litterial Green           52           12.0            4.5   \n",
       "1339        Jon Barry           47           11.7            4.4   \n",
       "\n",
       "      FieldGoalsMade  FieldGoalsAttempt  FieldGoalPercent  3PointMade  \\\n",
       "0                2.6                7.6              34.7         0.5   \n",
       "1                2.0                6.7              29.6         0.7   \n",
       "2                2.0                4.7              42.2         0.4   \n",
       "3                2.3                5.5              42.6         0.1   \n",
       "4                1.6                3.0              52.4         0.0   \n",
       "...              ...                ...               ...         ...   \n",
       "1335             1.6                3.6              43.3         0.0   \n",
       "1336             1.5                4.1              35.8         0.1   \n",
       "1337             2.2                3.9              55.0         0.0   \n",
       "1338             1.7                3.8              43.9         0.0   \n",
       "1339             1.6                4.4              36.9         0.4   \n",
       "\n",
       "      3PointAttempt  3PointPercent  ...  FreeThrowAttempt  FreeThrowPercent  \\\n",
       "0               2.1           25.0  ...               2.3              69.9   \n",
       "1               2.8           23.5  ...               3.4              76.5   \n",
       "2               1.7           24.4  ...               1.3              67.0   \n",
       "3               0.5           22.6  ...               1.3              68.9   \n",
       "4               0.1            0.0  ...               1.9              67.4   \n",
       "...             ...            ...  ...               ...               ...   \n",
       "1335            0.2           14.3  ...               1.5              79.2   \n",
       "1336            0.7           16.7  ...               1.0              79.4   \n",
       "1337            0.0            0.0  ...               1.6              64.3   \n",
       "1338            0.2           10.0  ...               1.8              62.5   \n",
       "1339            1.3           33.3  ...               1.0              67.3   \n",
       "\n",
       "      OffensiveRebounds  DefensiveRebounds  Rebounds  Assists  Steals  Blocks  \\\n",
       "0                   0.7                3.4       4.1      1.9     0.4     0.4   \n",
       "1                   0.5                2.0       2.4      3.7     1.1     0.5   \n",
       "2                   0.5                1.7       2.2      1.0     0.5     0.3   \n",
       "3                   1.0                0.9       1.9      0.8     0.6     0.1   \n",
       "4                   1.0                1.5       2.5      0.3     0.3     0.4   \n",
       "...                 ...                ...       ...      ...     ...     ...   \n",
       "1335                0.4                0.8       1.2      2.5     0.6     0.2   \n",
       "1336                0.4                1.1       1.5      2.3     0.8     0.0   \n",
       "1337                1.5                2.3       3.8      0.3     0.3     0.4   \n",
       "1338                0.2                0.4       0.7      2.2     0.4     0.1   \n",
       "1339                0.2                0.7       0.9      1.4     0.7     0.1   \n",
       "\n",
       "      Turnovers  Target  \n",
       "0           1.3       0  \n",
       "1           1.6       0  \n",
       "2           1.0       0  \n",
       "3           1.0       1  \n",
       "4           0.8       1  \n",
       "...         ...     ...  \n",
       "1335        0.8       0  \n",
       "1336        1.3       1  \n",
       "1337        0.9       0  \n",
       "1338        0.8       1  \n",
       "1339        0.9       1  \n",
       "\n",
       "[1340 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = pd.read_csv('sports.csv')\n",
    "sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  object\n",
       "GamesPlayed            int64\n",
       "MinutesPlayed        float64\n",
       "PointsPerGame        float64\n",
       "FieldGoalsMade       float64\n",
       "FieldGoalsAttempt    float64\n",
       "FieldGoalPercent     float64\n",
       "3PointMade           float64\n",
       "3PointAttempt        float64\n",
       "3PointPercent        float64\n",
       "FreeThrowMade        float64\n",
       "FreeThrowAttempt     float64\n",
       "FreeThrowPercent     float64\n",
       "OffensiveRebounds    float64\n",
       "DefensiveRebounds    float64\n",
       "Rebounds             float64\n",
       "Assists              float64\n",
       "Steals               float64\n",
       "Blocks               float64\n",
       "Turnovers            float64\n",
       "Target                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
