{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb2481b",
   "metadata": {},
   "source": [
    "### Como utilizar ML com Dados Não Estruturais Textuais?\n",
    "\n",
    "* Técnicas de NLP preprocessam os dados para filtrarmos o que é mais relevante para a classificação \n",
    "\n",
    "![Title](../imgs/nlp-illustration.png)\n",
    "\n",
    "\n",
    "* A tokenização nos auxilia a dividir strings em palavras\n",
    "* Essas palavras serão as \"features\" que serão utilizadas para aprendizado de um modelo de Machine Learning\n",
    "* Um algoritmo de Machine Learning só entende números (atributos sempre numéricos), sendo assim, após a tokenização, precisamos converter nossas palavras para valores numéricos\n",
    "* O processo de transformação textual para base numérico denomina-se **bag of words**\n",
    "\n",
    "![Title](../imgs/1-Bag-of-words.png)\n",
    "\n",
    "* Técnicas como TF-IDF e CountVectorizer, apesar de eficientes, transformam o dataset em dado tabular\n",
    "  * Cada coluna é uma palavra\n",
    "  * Quando a palavra existir em uma dada amostra, substituimos o valor 0 pela frequência em que aquela palavra ocorre no texto\n",
    "  \n",
    "  <img src=\"https://www.researchgate.net/profile/Haider-Al-Khateeb/publication/291950178/figure/fig1/AS:330186932408324@1455734107458/Term-Frequency-Inverse-Document-Frequency-TF-IDF.png\" width=800>\n",
    "  \n",
    "* A consequencia disso é a perda da relação semântica nas frases\n",
    "* Perda de contexto das sentenças\n",
    "* Vocabulário imenso (maldição da dimensionalidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409191a",
   "metadata": {},
   "source": [
    "### Word Embeddings to rescue!\n",
    "\n",
    "* Vetor multidimensional de palavras\n",
    "* Mapa de características com a frequência de palavras e considerações semânticas \n",
    "* Baseado em similaridade\n",
    "* Aprendizado por meio de redes neurais\n",
    "\n",
    "##### Como fazemos isso?\n",
    "* Dada uma palavra da frase\n",
    "* Pegar as palavras vizinhas \n",
    "* Rede Neural irá calcular a probabilidade dessa palavra vizinha ser a palavra a ser predita\n",
    "* Selecionamos as palavras vizinhas definindo uma \"janela\" ou \"kernel\"\n",
    "  * Janela = 2 considere duas palavras ao redor da palavra atual\n",
    "![Title](../imgs/training_data.png)\n",
    "\n",
    "* Criamos um corpus com as palavras organizadas de acordo com as janelas em torno do dataset.\n",
    "* Palavras que aparecerem juntas tem maior probabilidade de terem significado semântico\n",
    "  * Exemplo: \"soviética\" provavelmente terá uma semelhança com união\n",
    "  \n",
    " ![Title](../imgs/vetor_multi.png)\n",
    " \n",
    "[Leitura adicional](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/): funcionamento de uma rede neural para embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2cec0",
   "metadata": {},
   "source": [
    "### Arquiteturas Word Embeddings\n",
    "\n",
    "* Existem diferentes formas de gerar nossas embeddings, gerando determinadas arquiteturas previamente conhecidos como CBOW e SkipGram. Essas arquiteturas também são denominadas como tipo word2vec (palavra para vetor)\n",
    "\n",
    "* CBOW: predizer uma palavra baseado nas palavras vizinhas. Mais rápido, funciona melhor nas palavras mais frequentes.\n",
    "* Skip-Gram: predizer o contexto baseado nas palavras vizinhas. Funciona melhor com datasets menores\n",
    "<img src=\"https://leimao.github.io/images/article/2019-08-23-Word2Vec-Classic/word2vec.png\">\n",
    "* Ambas arquiteturas tem uma ambientação semelhante, modificando a forma como a saída e a entrada são organizadas\n",
    "* Exemplo: Hoje vai fazer sol pela manhã com pancadas de chuva à tarde\n",
    "* Utilizando CBOW\n",
    "![Title](../imgs/cbow.png)\n",
    "* Utilizando Skip-Gram\n",
    "![Title](../imgs/skip_gram.png)\n",
    "\n",
    "[Leitura adicional](https://www.tensorflow.org/tutorials/text/word2vec): transformando o corpus do CBOW/skip_gram em numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bc7c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Baixa as listas de stopwords e as tokenizações\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define as stopwords em inglês\n",
    "sw_english = set(stopwords.words('english'))\n",
    "\n",
    "# Instância o PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Carrega o conjunto de dados\n",
    "movies = pd.read_csv('../datasets/movies.csv', index_col = 0)\n",
    "\n",
    "# Retira uma amostra do conjunto de dados\n",
    "movies_sample = movies.sample(frac = 0.1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a55385c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um pipeline\n",
    "def preprocessing(string):\n",
    "    ###\n",
    "    # Deixa apenas elementos alfanuméricos\n",
    "    string = re.sub(r\"[^a-zA-Z0-9]+\", ' ', string)\n",
    "    ###\n",
    "    # deixa todas as palavras minúsculas\n",
    "    string = string.lower()\n",
    "    ###\n",
    "    # tokenização\n",
    "    words = word_tokenize(string)\n",
    "    ###\n",
    "    # Remove Stopwords\n",
    "    filtered_words = []\n",
    "    for w in words:\n",
    "        if w not in sw_english:\n",
    "            filtered_words.append(w)\n",
    "    ###\n",
    "    # Aplica o Stemming\n",
    "    stem_words = []\n",
    "    for w in filtered_words:\n",
    "        s_words = stemmer.stem(w)\n",
    "        stem_words.append(s_words)\n",
    "    ###\n",
    "    # Retorna a lista de palavras pré-processadas\n",
    "    return stem_words\n",
    "\n",
    "# Aplica o preprocessing nas críticas de filmes\n",
    "movies_sample[\"filtered_words\"] = movies_sample['text'].apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "435df28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36151</th>\n",
       "      <td>Well let me just say something about these act...</td>\n",
       "      <td>1</td>\n",
       "      <td>[well, let, say, someth, actor, realli, good, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31632</th>\n",
       "      <td>Now we know where they got the idea of Snakes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[know, got, idea, snake, plane, put, bluntli, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13602</th>\n",
       "      <td>This was a great movie, and safe for the entir...</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, movi, safe, entir, famili, one, see, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22447</th>\n",
       "      <td>Myron Breckinridge (Rex Reed!!!) gets a sex ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>[myron, breckinridg, rex, reed, get, sex, chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>I absolutely despise this movie. No wonder Jos...</td>\n",
       "      <td>0</td>\n",
       "      <td>[absolut, despis, movi, wonder, jose, larraz, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27014</th>\n",
       "      <td>despite the occasionally stilted acting and \"s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[despit, occasion, stilt, act, seen, stori, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>I like a lot of Myrna Loy movies. This film wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[like, lot, myrna, loy, movi, film, produc, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13917</th>\n",
       "      <td>This film quite literally has every single act...</td>\n",
       "      <td>1</td>\n",
       "      <td>[film, quit, liter, everi, singl, action, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>This movie is without a doubt the worst horror...</td>\n",
       "      <td>0</td>\n",
       "      <td>[movi, without, doubt, worst, horror, movi, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>Michael Bassett's film 'Solomon Kane' (based o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[michael, bassett, film, solomon, kane, base, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "36151  Well let me just say something about these act...      1   \n",
       "31632  Now we know where they got the idea of Snakes ...      0   \n",
       "13602  This was a great movie, and safe for the entir...      1   \n",
       "22447  Myron Breckinridge (Rex Reed!!!) gets a sex ch...      0   \n",
       "36511  I absolutely despise this movie. No wonder Jos...      0   \n",
       "...                                                  ...    ...   \n",
       "27014  despite the occasionally stilted acting and \"s...      1   \n",
       "2802   I like a lot of Myrna Loy movies. This film wa...      0   \n",
       "13917  This film quite literally has every single act...      1   \n",
       "3696   This movie is without a doubt the worst horror...      0   \n",
       "3954   Michael Bassett's film 'Solomon Kane' (based o...      0   \n",
       "\n",
       "                                          filtered_words  \n",
       "36151  [well, let, say, someth, actor, realli, good, ...  \n",
       "31632  [know, got, idea, snake, plane, put, bluntli, ...  \n",
       "13602  [great, movi, safe, entir, famili, one, see, m...  \n",
       "22447  [myron, breckinridg, rex, reed, get, sex, chan...  \n",
       "36511  [absolut, despis, movi, wonder, jose, larraz, ...  \n",
       "...                                                  ...  \n",
       "27014  [despit, occasion, stilt, act, seen, stori, fa...  \n",
       "2802   [like, lot, myrna, loy, movi, film, produc, ch...  \n",
       "13917  [film, quit, liter, everi, singl, action, movi...  \n",
       "3696   [movi, without, doubt, worst, horror, movi, ev...  \n",
       "3954   [michael, bassett, film, solomon, kane, base, ...  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad6e00",
   "metadata": {},
   "source": [
    "### Treinamento de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9babb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
