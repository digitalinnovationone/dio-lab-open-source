{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849d3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plot\n",
    "from random import randint\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c339b",
   "metadata": {},
   "source": [
    "#### Introdução a Redes Neurais\n",
    "\n",
    "* Algoritmo de aprendizagem de máquina inspirado no neurônio biológico, possuindo uma estrutura básica chamada neurônio\n",
    "\n",
    "1. Neurônio biológico\n",
    "\n",
    "![Title](../imgs/neuronio.jpg)\n",
    "\n",
    "2. Neurônio de uma rede neural (perceptron)\n",
    "\n",
    "* Estrutura com pesos para cada entrada\n",
    "* Objetivo de encontrar os melhores pesos para classificar um problema\n",
    "* Funciona apenas para problemas linearmente separáveis\n",
    "\n",
    "![Title](../imgs/perceptron.png)\n",
    "\n",
    "3. Para formar uma rede neural propriamente dita, tem-se um conjunto de neurônios\n",
    "* Múltiplos neurônios formam uma camada\n",
    "* Possibilidade de resolver problemas que não são linearmente separáveis\n",
    "![Title](../imgs/rn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk import pos_tag\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9df8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras as keras\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0476ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Instancia o PorterStemmer\n",
    "stemmer = PorterStemmer()                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becfca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../datasets/movies.csv', index_col=0)\n",
    "movies_sample = movies.sample(frac=0.1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e315b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(string):\n",
    "    ###\n",
    "    # Remove acentuações\n",
    "    string = unidecode(string)\n",
    "    ###\n",
    "    # Deixa apenas elementos alfanuméricos\n",
    "    string = re.sub(r\"[^a-zA-Z0-9]+\", ' ', string)\n",
    "    ###\n",
    "    # deixa todas as palavras minúsculas\n",
    "    string = string.lower()\n",
    "    ###\n",
    "    # tokenização\n",
    "    words = word_tokenize(string)\n",
    "    ###\n",
    "    # Remove Stopwords\n",
    "    filtered_words = []\n",
    "    for w in words:\n",
    "        if w not in stopwords:\n",
    "            filtered_words.append(w)\n",
    "    ###\n",
    "    # Aplica o Stemming\n",
    "    stem_words = []\n",
    "    for w in filtered_words:\n",
    "        s_words = stemmer.stem(w)\n",
    "        stem_words.append(s_words)\n",
    "    ###\n",
    "    # Retorna a lista de palavras pré-processadas\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfaf21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o preprocessing nas críticas de filmes\n",
    "movies_sample[\"filtered_words\"] = movies_sample['text'].apply(lambda x: preprocessing(x))\n",
    "\n",
    "# Normalmente, depois do processamento juntamos as palavras novamente em uma só string\n",
    "movies_sample['join_words'] = movies_sample['filtered_words'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd7d8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados em X e Y\n",
    "X = movies_sample['join_words']\n",
    "y = movies_sample['label']\n",
    "\n",
    "# Carrega o train_test_split para separar a base em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa os dados em treino e teste\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                     y,\n",
    "                                                     test_size = 0.3,\n",
    "                                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f99e1",
   "metadata": {},
   "source": [
    "### Usando Contadores de Frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd4b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a função CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instancia o transformador\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Transforma os dados nas matrizes de saída\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_val_cv = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21f996d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame(X_train_cv, columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "812cfc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000000000001</th>\n",
       "      <th>0069</th>\n",
       "      <th>007</th>\n",
       "      <th>0080</th>\n",
       "      <th>0083</th>\n",
       "      <th>0093638</th>\n",
       "      <th>00schneider</th>\n",
       "      <th>01</th>\n",
       "      <th>...</th>\n",
       "      <th>zugsmith</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zungia</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zweit</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zy</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 22934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0000000000001  0069  007  0080  0083  0093638  00schneider  01  \\\n",
       "0      0    0              0     0    0     0     0        0            0   0   \n",
       "1      0    0              0     0    0     0     0        0            0   0   \n",
       "2      0    0              0     0    0     0     0        0            0   0   \n",
       "3      0    0              0     0    0     0     0        0            0   0   \n",
       "4      0    0              0     0    0     0     0        0            0   0   \n",
       "...   ..  ...            ...   ...  ...   ...   ...      ...          ...  ..   \n",
       "3495   0    0              0     0    0     0     0        0            0   0   \n",
       "3496   0    0              0     0    0     0     0        0            0   0   \n",
       "3497   0    0              0     0    0     0     0        0            0   0   \n",
       "3498   0    0              0     0    0     0     0        0            0   0   \n",
       "3499   0    0              0     0    0     0     0        0            0   0   \n",
       "\n",
       "      ...  zugsmith  zulu  zungia  zwart  zweit  zwick  zy  \\\n",
       "0     ...         0     0       0      0      0      0   0   \n",
       "1     ...         0     0       0      0      0      0   0   \n",
       "2     ...         0     0       0      0      0      0   0   \n",
       "3     ...         0     0       0      0      0      0   0   \n",
       "4     ...         0     0       0      0      0      0   0   \n",
       "...   ...       ...   ...     ...    ...    ...    ...  ..   \n",
       "3495  ...         0     0       0      0      0      0   0   \n",
       "3496  ...         0     0       0      0      0      0   0   \n",
       "3497  ...         0     0       0      0      0      0   0   \n",
       "3498  ...         0     0       0      0      0      0   0   \n",
       "3499  ...         0     0       0      0      0      0   0   \n",
       "\n",
       "      zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "...                               ...   \n",
       "3495                                0   \n",
       "3496                                0   \n",
       "3497                                0   \n",
       "3498                                0   \n",
       "3499                                0   \n",
       "\n",
       "      zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "3495                                          0   \n",
       "3496                                          0   \n",
       "3497                                          0   \n",
       "3498                                          0   \n",
       "3499                                          0   \n",
       "\n",
       "      zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \n",
       "0                                                0  \n",
       "1                                                0  \n",
       "2                                                0  \n",
       "3                                                0  \n",
       "4                                                0  \n",
       "...                                            ...  \n",
       "3495                                             0  \n",
       "3496                                             0  \n",
       "3497                                             0  \n",
       "3498                                             0  \n",
       "3499                                             0  \n",
       "\n",
       "[3500 rows x 22934 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d74eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = \"relu\", input_shape=(df_cv.shape[1],)))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15cd7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e80a47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 17:46:49.462203: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6299 - accuracy: 0.7083 - val_loss: 0.5305 - val_accuracy: 0.8093\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.3674 - accuracy: 0.9126 - val_loss: 0.4021 - val_accuracy: 0.8453\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    " X_train_cv, y_train,\n",
    " epochs= 2,\n",
    " batch_size = 500,\n",
    " validation_data = (X_val_cv, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5cc4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273333311080933\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c86577",
   "metadata": {},
   "source": [
    "### Usando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a8ba752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29776    infam pre code film realli one film caus peopl...\n",
       "929      watch movi hope find pretti interest stori yet...\n",
       "17389    realli make video nasti guis digit wide screen...\n",
       "14675    okay bore decid see movi think main thing brou...\n",
       "33304    wow first five minut watch film quit tempt put...\n",
       "                               ...                        \n",
       "36400    must seen movi one comment refer first think s...\n",
       "34958    kite runner one controversi film year one cont...\n",
       "26497    pretti much first jason scott lee film seen sa...\n",
       "10215    mayb saw movi read book realli love movi seen ...\n",
       "18609    hobgoblin hobgoblin begin br br film give mano...\n",
       "Name: join_words, Length: 3500, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfcd90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80  \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdca972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados em X e Y\n",
    "X = movies_sample['filtered_words']\n",
    "y = movies_sample['label']\n",
    "\n",
    "# Carrega o train_test_split para separar a base em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa os dados em treino e teste\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                     y,\n",
    "                                                     test_size = 0.3,\n",
    "                                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54493c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80c5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12b0d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(sequences,maxlen=max_length)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "val_padded = pad_sequences(val_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a3409fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5342cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1a7b186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5186 - val_loss: 0.6843 - val_accuracy: 0.5933\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8703 - val_loss: 0.4528 - val_accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9940 - val_loss: 0.5636 - val_accuracy: 0.7973\n",
      "Epoch 4/5\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8040\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 6.3115e-04 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    " padded, y_train,\n",
    " epochs= 5,\n",
    " batch_size = 64,\n",
    " validation_data = (val_padded, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627dd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
