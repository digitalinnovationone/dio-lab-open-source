{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de7cecd",
   "metadata": {},
   "source": [
    "Crie uma classe que seja capaz de:\n",
    "\n",
    "- Metodo para remover acentuação\n",
    "- Metodo de remover digitos\n",
    "- Metodo de remover caracteres especiais\n",
    "- Metodo de normalizar o texto em caixa baixa\n",
    "- Metodo para criar os tokens\n",
    "- Metodo para filtrar stopwords\n",
    "- Metodo para pegar o stemming\n",
    "- Metodo para pegar o lemma\n",
    "- Metodo de pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "711b0e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:25:37.616316Z",
     "start_time": "2022-08-27T19:25:37.612313Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import RSLPStemmer\n",
    "import spacy\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "words_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6d7b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:25:43.208265Z",
     "start_time": "2022-08-27T19:25:42.667785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>This is the kind of picture John Lassiter woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>A MUST SEE! I saw WHIPPED at a press screening...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NBC should be ashamed. I wouldn't allow my chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>This movie is a clumsy mishmash of various gho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Formula movie about the illegitimate son of a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     I grew up (b. 1965) watching and loving the Th...      0\n",
       "1     When I put this movie in my DVD player, and sa...      0\n",
       "2     Why do people who do not know what a particula...      0\n",
       "3     Even though I have great interest in Biblical ...      0\n",
       "4     Im a die hard Dads Army fan and nothing will e...      1\n",
       "...                                                 ...    ...\n",
       "4995  This is the kind of picture John Lassiter woul...      1\n",
       "4996  A MUST SEE! I saw WHIPPED at a press screening...      1\n",
       "4997  NBC should be ashamed. I wouldn't allow my chi...      0\n",
       "4998  This movie is a clumsy mishmash of various gho...      0\n",
       "4999  Formula movie about the illegitimate son of a ...      0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('../dataset/movies.csv', index_col=0)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e7dad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:25:43.223968Z",
     "start_time": "2022-08-27T19:25:43.209266Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_sample = movies.sample(frac=0.1, replace=False, ignore_index=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a936f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:25:43.239982Z",
     "start_time": "2022-08-27T19:25:43.224968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The storyline was okay. Akshay Kumar was good ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, well, no one in their right mind(s) would ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punishment Park is a pseudo-documentary made b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why take a show that millions of us watched an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Even if you could get past the idea that these...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>I can't believe I watched this expecting more....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Where the Rivers Flow North is a well-told sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>The film really challenges your notions of ide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>i totally disagree with the person who first c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"FULL HOUSE,\" in my opinion, is an absolute AB...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     The storyline was okay. Akshay Kumar was good ...      0\n",
       "1     OK, well, no one in their right mind(s) would ...      1\n",
       "2     Punishment Park is a pseudo-documentary made b...      1\n",
       "3     Why take a show that millions of us watched an...      0\n",
       "4     Even if you could get past the idea that these...      0\n",
       "...                                                 ...    ...\n",
       "4995  I can't believe I watched this expecting more....      0\n",
       "4996  Where the Rivers Flow North is a well-told sto...      1\n",
       "4997  The film really challenges your notions of ide...      1\n",
       "4998  i totally disagree with the person who first c...      1\n",
       "4999  \"FULL HOUSE,\" in my opinion, is an absolute AB...      1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddc9ced8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:30:27.214032Z",
     "start_time": "2022-08-27T19:30:27.190507Z"
    }
   },
   "outputs": [],
   "source": [
    "class dados:\n",
    "    \"\"\"classe para limpar dados\"\"\"\n",
    "    limpa_dados = \"msg\"\n",
    "    \n",
    "    def __init__(self, texto):\n",
    "        \"\"\"inicio da função\"\"\"\n",
    "        self.texto = texto\n",
    "        print(f\"tratamento para as informações :{self.texto}\\n\")\n",
    "        \n",
    "    def acentuacao(self, acento):\n",
    "        \"\"\"Metodo para remover acentuação\"\"\"\n",
    "        \n",
    "        self.acento = acento\n",
    "        return unidecode.unidecode(self.acento)\n",
    "        \n",
    "    def digito(self, digito):\n",
    "        \"\"\"Metodo de remover digitos\"\"\"\n",
    "        \n",
    "        self.digito = digito\n",
    "        return re.sub(r'\\d', '', self.digito)\n",
    "        \n",
    "    def caractere(self, caracter):\n",
    "        \"\"\"Metodo de remover caracteres especiais\"\"\"\n",
    "        \n",
    "        self.caracter = caracter\n",
    "        return re.sub(r'\\W',' ', self.caracter)      \n",
    "    \n",
    "    def minusculo_lower(self, baixa):\n",
    "        \"\"\"Metodo de normalizar o texto em caixa baixa\"\"\"\n",
    "        \n",
    "        self.baixa = baixa\n",
    "        return self.baixa.lower()\n",
    "        \n",
    "    def tokens(self, token):\n",
    "        \"\"\"Metodo para criar os tokens\"\"\"\n",
    "        \n",
    "        self.token = token\n",
    "        return word_tokenize(self.token)\n",
    "    \n",
    "    def remove_stopwords(self, entrada, idioma):\n",
    "        \"\"\"filtrar entrada digite o idioma ingles, portugues\"\"\"\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        #words_en = stopwords.words('english')\n",
    "        self.entrada = entrada\n",
    "        self.idioma = idioma\n",
    "        lista = []\n",
    "        \n",
    "        if self.idioma == \"ingles\":            \n",
    "            for word in self.entrada:\n",
    "                if not word in stopwords:\n",
    "                    lista.append(word)                \n",
    "\n",
    "        \n",
    "        elif self.idioma == \"portugues\":            \n",
    "            for word in self.entrada:\n",
    "                if not word in words_pt:\n",
    "                    lista.append(word) \n",
    "                           \n",
    "        else:\n",
    "            print(\"1° tabela com processamento stopwords depois, Digite o idioma ingles ou portugues.\")\n",
    "            \n",
    "        \n",
    "        return lista\n",
    "    \n",
    "          \n",
    "    \n",
    "    def stemmer(self, stem):\n",
    "        \"\"\"Metodo para pegar o stemming\"\"\"\n",
    "        \n",
    "        stemmer = RSLPStemmer()\n",
    "        stemer = PorterStemmer()        \n",
    "        self.stem = stem\n",
    "        \n",
    "        \n",
    "        stem_words = []\n",
    "        \n",
    "        for w in self.stem:\n",
    "            s_words = stemmer.stem(w)\n",
    "            stem_words.append(s_words)\n",
    "                \n",
    "                \n",
    "        return stem_words\n",
    "        \n",
    "    def lemmatizacao(self, lemm):\n",
    "        \"\"\"Metodo para pegar o lemmatizacao\"\"\"\n",
    "        \n",
    "        self.lemm = lemm\n",
    "        \n",
    "        pt_core = spacy.load(\"pt_core_news_sm\")\n",
    "        \n",
    "        min_frase = []\n",
    "        minimo = pt_core(str([palavra for palavra in self.lemm]))\n",
    "        min_frase.append([token.lemma_ for token in minimo if token.pos_ == 'NOUN'])\n",
    "        \n",
    "        return min_frase\n",
    "    \n",
    "    def pipeline(self, pipe, texto):\n",
    "        \"\"\"pipe para saida dos metodos\"\"\"\n",
    "        \n",
    "        self.pipe = pipe\n",
    "        self.texto = texto\n",
    "        tratamento = {\"acentuacao\":self.acentuacao,\n",
    "                     \"digito\":self.digito,\n",
    "                     \"caractere\":self.caracter,\n",
    "                     \"minusculo_lower\":self.minusculo_lower,\n",
    "                     \"tokens\":self.tokens,\n",
    "                     \"remove_stopwords\":self.remove_stopwords,\n",
    "                     \"stemmer\":self.stemmer,\n",
    "                     \"lemmatizacao\":self.lemmatizacao}\n",
    "        \n",
    "        for i in self.pipe:\n",
    "            saida = tratamento[i](self.text)\n",
    "    \n",
    "        return saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14c43c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:30:27.757513Z",
     "start_time": "2022-08-27T19:30:27.749506Z"
    }
   },
   "outputs": [],
   "source": [
    "frase = 'Fui para ver este100 200 300 filme com cautela Uma comédia / / * #suicida Não parecia consistente Ter um irmão que tentou suicídio e ver a devastação que causou toda a nossa família Eu sei em primeira mão como pode ser esmagador lidar com esse problema. devo dizer Este filme lida com isso de uma maneira que permite ao espectador dentro de alguém que está sofrendo e simplesmente não sabe por que ou como pará-lo Embora o filme não seja perfeito, ele respeita o assunto e, mais importante, o torna acessível para as massas Eu sei que para a nossa família o humor tem nos ajudado a passar por muita dor E Max e Grace é exatamente o que prenuncia ser uma COMÉDIA suicida É engraçado E eu também senti que os personagens eram reais e vibrantes Também é extremamente inteligente, mas simples vai direto ao ponto e eu aprecio que eu dou um e recomendo '\n",
    "idioma = \"ingles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4adec260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:30:28.469710Z",
     "start_time": "2022-08-27T19:30:28.061506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tratamento para as informações :Fui para ver este100 200 300 filme com cautela Uma comédia / / * #suicida Não parecia consistente Ter um irmão que tentou suicídio e ver a devastação que causou toda a nossa família Eu sei em primeira mão como pode ser esmagador lidar com esse problema. devo dizer Este filme lida com isso de uma maneira que permite ao espectador dentro de alguém que está sofrendo e simplesmente não sabe por que ou como pará-lo Embora o filme não seja perfeito, ele respeita o assunto e, mais importante, o torna acessível para as massas Eu sei que para a nossa família o humor tem nos ajudado a passar por muita dor E Max e Grace é exatamente o que prenuncia ser uma COMÉDIA suicida É engraçado E eu também senti que os personagens eram reais e vibrantes Também é extremamente inteligente, mas simples vai direto ao ponto e eu aprecio que eu dou um e recomendo \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wiltd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['filme',\n",
       "  'cautela',\n",
       "  'comédia',\n",
       "  '#',\n",
       "  'irmão',\n",
       "  'suicídio',\n",
       "  'devastação',\n",
       "  'família',\n",
       "  'mão',\n",
       "  'esmagador',\n",
       "  'problema',\n",
       "  'filme',\n",
       "  'maneira',\n",
       "  'espectador',\n",
       "  'filme',\n",
       "  'assunto',\n",
       "  'massa',\n",
       "  'família',\n",
       "  'dor',\n",
       "  'prenuncia',\n",
       "  'personagem',\n",
       "  'real',\n",
       "  'vibrante',\n",
       "  'ponto',\n",
       "  'recomendo']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frase = movies_sample[\"text\"][0]\n",
    "teste = dados(frase)\n",
    "teste_tokens = teste.tokens(frase)\n",
    "stop = teste.remove_stopwords(teste_tokens, idioma)\n",
    "lemm = teste.stemmer(stop)\n",
    "teste.lemmatizacao(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c69e5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-27T19:30:35.168537Z",
     "start_time": "2022-08-27T19:30:35.125498Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tratamento para as informações :                                                   text  label\n",
      "0     The storyline was okay. Akshay Kumar was good ...      0\n",
      "1     OK, well, no one in their right mind(s) would ...      1\n",
      "2     Punishment Park is a pseudo-documentary made b...      1\n",
      "3     Why take a show that millions of us watched an...      0\n",
      "4     Even if you could get past the idea that these...      0\n",
      "...                                                 ...    ...\n",
      "4995  I can't believe I watched this expecting more....      0\n",
      "4996  Where the Rivers Flow North is a well-told sto...      1\n",
      "4997  The film really challenges your notions of ide...      1\n",
      "4998  i totally disagree with the person who first c...      1\n",
      "4999  \"FULL HOUSE,\" in my opinion, is an absolute AB...      1\n",
      "\n",
      "[5000 rows x 2 columns]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dados.pipeline() got an unexpected keyword argument 'methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m dados(movies_sample)\n\u001b[0;32m      2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdigito\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaractere\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove_stopwords\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m movies_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiltered_words\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmovies_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m movies_sample\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:138\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: dados.pipeline() got an unexpected keyword argument 'methods'"
     ]
    }
   ],
   "source": [
    "preprocess = dados(movies_sample)\n",
    "pipeline = [\n",
    "    'digito',\n",
    "    'caractere',\n",
    "    'minusculo_lower',\n",
    "    'tokens',\n",
    "    'remove_stopwords',\n",
    "    'stemmer']\n",
    "\n",
    "movies_sample[\"filtered_words\"] = movies_sample['text'].apply(preprocess.pipeline, methods=pipeline)\n",
    "movies_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa1417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7366c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37590be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
