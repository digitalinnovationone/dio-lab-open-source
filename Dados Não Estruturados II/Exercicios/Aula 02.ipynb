{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de7cecd",
   "metadata": {},
   "source": [
    "Crie uma classe que seja capaz de:\n",
    "\n",
    "- Metodo para remover acentuação\n",
    "- Metodo de remover digitos\n",
    "- Metodo de remover caracteres especiais\n",
    "- Metodo de normalizar o texto em caixa baixa\n",
    "- Metodo para criar os tokens\n",
    "- Metodo para filtrar stopwords\n",
    "- Metodo para pegar o stemming\n",
    "- Metodo para pegar o lemma\n",
    "- Metodo de pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "711b0e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:16:03.599297Z",
     "start_time": "2022-08-31T01:16:03.077835Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import RSLPStemmer\n",
    "import spacy\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "words_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "from sklearn.pipeline import Pipeline\n",
    "pt_core = spacy.load(\"pt_core_news_sm\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6d7b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T22:01:26.070937Z",
     "start_time": "2022-08-30T22:01:25.533839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>This is the kind of picture John Lassiter woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>A MUST SEE! I saw WHIPPED at a press screening...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NBC should be ashamed. I wouldn't allow my chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>This movie is a clumsy mishmash of various gho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Formula movie about the illegitimate son of a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     I grew up (b. 1965) watching and loving the Th...      0\n",
       "1     When I put this movie in my DVD player, and sa...      0\n",
       "2     Why do people who do not know what a particula...      0\n",
       "3     Even though I have great interest in Biblical ...      0\n",
       "4     Im a die hard Dads Army fan and nothing will e...      1\n",
       "...                                                 ...    ...\n",
       "4995  This is the kind of picture John Lassiter woul...      1\n",
       "4996  A MUST SEE! I saw WHIPPED at a press screening...      1\n",
       "4997  NBC should be ashamed. I wouldn't allow my chi...      0\n",
       "4998  This movie is a clumsy mishmash of various gho...      0\n",
       "4999  Formula movie about the illegitimate son of a ...      0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('../dataset/movies.csv', index_col=0)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e7dad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T22:01:26.090054Z",
     "start_time": "2022-08-30T22:01:26.070937Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_sample = movies.sample(frac=0.1, replace=False, ignore_index=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a936f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-30T22:01:26.105488Z",
     "start_time": "2022-08-30T22:01:26.090054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It used to be my thinking that movies required...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given that a lot of horror films are based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went into this movie with very little in ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picking this up along with the rest of the Mar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was really surprised with this movie. Going ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Bo Derek's beauty and John Derek's revolutiona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>What a terrible movie! The acting in this film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>A film about an interesting and sensitive peri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>I was never in the past interested in this pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Movies like these do not need sequels. Part of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     It used to be my thinking that movies required...      0\n",
       "1     Given that a lot of horror films are based on ...      0\n",
       "2     I went into this movie with very little in ter...      0\n",
       "3     Picking this up along with the rest of the Mar...      0\n",
       "4     I was really surprised with this movie. Going ...      1\n",
       "...                                                 ...    ...\n",
       "4995  Bo Derek's beauty and John Derek's revolutiona...      1\n",
       "4996  What a terrible movie! The acting in this film...      0\n",
       "4997  A film about an interesting and sensitive peri...      0\n",
       "4998  I was never in the past interested in this pla...      1\n",
       "4999  Movies like these do not need sequels. Part of...      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddc9ced8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:24:23.511163Z",
     "start_time": "2022-08-31T01:24:23.494148Z"
    }
   },
   "outputs": [],
   "source": [
    "class dados:\n",
    "    \"\"\"classe para limpar dados\"\"\"\n",
    "    limpa_dados = \"msg\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"inicio da função\"\"\"\n",
    "        #self.texto = texto\n",
    "        #print(f\"tratamento para as informações :{self.texto}\\n\")\n",
    "        \n",
    "    def acentuacao(self, acento):\n",
    "        \"\"\"Metodo para remover acentuação\"\"\"\n",
    "        \n",
    "        self.acento = acento\n",
    "        return unidecode.unidecode(self.acento)\n",
    "        \n",
    "    def digito(self, digi):\n",
    "        \"\"\"Metodo de remover digitos\"\"\"\n",
    "        \n",
    "        self.digi = digi\n",
    "        digi = re.sub(r'\\d', '', self.digi)\n",
    "        \n",
    "        return digi\n",
    "    \n",
    "    def caractere(self, caracter):\n",
    "        \"\"\"Metodo de remover caracteres especiais\"\"\"\n",
    "        \n",
    "        self.caracter = caracter\n",
    "        saida  = re.sub(r'\\W',' ', self.caracter)      \n",
    "        return saida\n",
    "    \n",
    "    def minusculo_lower(self, baixa):\n",
    "        \"\"\"Metodo de normalizar o texto em caixa baixa\"\"\"\n",
    "        \n",
    "        self.baixa = baixa\n",
    "        saida = self.baixa.lower()\n",
    "        return saida\n",
    "    \n",
    "    def tokens(self, token):\n",
    "        \"\"\"Metodo para criar os tokens\"\"\"\n",
    "        \n",
    "        self.token = token\n",
    "        saida = word_tokenize(self.token)\n",
    "        return saida\n",
    "    \n",
    "    def remove_stopwords(self, entrada, idioma =\"ingles\"):\n",
    "        \"\"\"filtrar entrada digite o idioma ingles, portugues\"\"\"\n",
    "        \n",
    "        \n",
    "        #words_en = stopwords.words('english')\n",
    "        self.entrada = entrada\n",
    "        self.idioma = idioma\n",
    "        lista = []\n",
    "        \n",
    "        if self.idioma == \"ingles\":            \n",
    "            for word in self.entrada:\n",
    "                if not word in stopwords:\n",
    "                    lista.append(word)                \n",
    "\n",
    "        \n",
    "        elif self.idioma == \"portugues\":            \n",
    "            for word in self.entrada:\n",
    "                if not word in words_pt:\n",
    "                    lista.append(word) \n",
    "                           \n",
    "        else:\n",
    "            print(\"1° tabela com processamento stopwords depois, Digite o idioma ingles ou portugues.\")\n",
    "            \n",
    "        \n",
    "        return lista\n",
    "    \n",
    "          \n",
    "    \n",
    "    def stemmer(self, stem):\n",
    "        \"\"\"Metodo para pegar o stemming\"\"\"\n",
    "        \n",
    "        stemmer = RSLPStemmer()\n",
    "        stemer = PorterStemmer()        \n",
    "        self.stem = stem\n",
    "        \n",
    "        \n",
    "        stem_words = []\n",
    "        \n",
    "        for w in self.stem:\n",
    "            s_words = stemmer.stem(w)\n",
    "            stem_words.append(s_words)\n",
    "                \n",
    "                \n",
    "        return stem_words\n",
    "        \n",
    "    def lemmatizacao(self, lemm):\n",
    "        \"\"\"Metodo para pegar o lemmatizacao\"\"\"\n",
    "        \n",
    "        self.lemm = lemm\n",
    "                \n",
    "        min_frase = []\n",
    "        minimo = pt_core(str([palavra for palavra in self.lemm]))\n",
    "        min_frase.append([token.lemma_ for token in minimo if token.pos_ == 'NOUN'])\n",
    "        \n",
    "        return min_frase\n",
    "    \n",
    "    def pipeline(self, text, methods):\n",
    "        \"\"\"pipe para saida dos metodos\"\"\"\n",
    "        \n",
    "        tratamento = {\"acentuacao\":self.acentuacao,\n",
    "                      \"digito\":self.digito,\n",
    "                      \"caractere\":self.caractere,\n",
    "                      \"minusculo_lower\":self.minusculo_lower,\n",
    "                      \"tokens\":self.tokens,\n",
    "                      \"remove_stopwords\":self.remove_stopwords,\n",
    "                      \"stemmer\":self.stemmer,\n",
    "                      \"lemmatizacao\":self.lemmatizacao}\n",
    "        #print(text)\n",
    "        for m in methods:\n",
    "            text = tratamento[m](text)\n",
    "            \n",
    "            return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf14e16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:03:40.613959Z",
     "start_time": "2022-08-31T01:03:40.596944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wiltd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fui',\n",
       " 'para',\n",
       " 'ver',\n",
       " 'este100',\n",
       " '200',\n",
       " '300',\n",
       " 'filme',\n",
       " 'com',\n",
       " 'cautela',\n",
       " 'Uma',\n",
       " 'comédia',\n",
       " '/',\n",
       " '/',\n",
       " '*',\n",
       " '#',\n",
       " 'suicida',\n",
       " 'Não',\n",
       " 'parecia',\n",
       " 'consistente',\n",
       " 'Ter',\n",
       " 'um',\n",
       " 'irmão',\n",
       " 'que',\n",
       " 'tentou',\n",
       " 'suicídio',\n",
       " 'e',\n",
       " 'ver',\n",
       " 'devastação',\n",
       " 'que',\n",
       " 'causou',\n",
       " 'toda',\n",
       " 'nossa',\n",
       " 'família',\n",
       " 'Eu',\n",
       " 'sei',\n",
       " 'em',\n",
       " 'primeira',\n",
       " 'mão',\n",
       " 'como',\n",
       " 'pode',\n",
       " 'ser',\n",
       " 'esmagador',\n",
       " 'lidar',\n",
       " 'com',\n",
       " 'esse',\n",
       " 'problema',\n",
       " '.',\n",
       " 'devo',\n",
       " 'dizer',\n",
       " 'Este',\n",
       " 'filme',\n",
       " 'lida',\n",
       " 'com',\n",
       " 'isso',\n",
       " 'de',\n",
       " 'uma',\n",
       " 'maneira',\n",
       " 'que',\n",
       " 'permite',\n",
       " 'ao',\n",
       " 'espectador',\n",
       " 'dentro',\n",
       " 'de',\n",
       " 'alguém',\n",
       " 'que',\n",
       " 'está',\n",
       " 'sofrendo',\n",
       " 'e',\n",
       " 'simplesmente',\n",
       " 'não',\n",
       " 'sabe',\n",
       " 'por',\n",
       " 'que',\n",
       " 'ou',\n",
       " 'como',\n",
       " 'pará-lo',\n",
       " 'Embora',\n",
       " 'filme',\n",
       " 'não',\n",
       " 'seja',\n",
       " 'perfeito',\n",
       " ',',\n",
       " 'ele',\n",
       " 'respeita',\n",
       " 'assunto',\n",
       " 'e',\n",
       " ',',\n",
       " 'mais',\n",
       " 'importante',\n",
       " ',',\n",
       " 'torna',\n",
       " 'acessível',\n",
       " 'para',\n",
       " 'massas',\n",
       " 'Eu',\n",
       " 'sei',\n",
       " 'que',\n",
       " 'para',\n",
       " 'nossa',\n",
       " 'família',\n",
       " 'humor',\n",
       " 'tem',\n",
       " 'nos',\n",
       " 'ajudado',\n",
       " 'passar',\n",
       " 'por',\n",
       " 'muita',\n",
       " 'dor',\n",
       " 'E',\n",
       " 'Max',\n",
       " 'e',\n",
       " 'Grace',\n",
       " 'é',\n",
       " 'exatamente',\n",
       " 'que',\n",
       " 'prenuncia',\n",
       " 'ser',\n",
       " 'uma',\n",
       " 'COMÉDIA',\n",
       " 'suicida',\n",
       " 'É',\n",
       " 'engraçado',\n",
       " 'E',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'senti',\n",
       " 'que',\n",
       " 'os',\n",
       " 'personagens',\n",
       " 'eram',\n",
       " 'reais',\n",
       " 'e',\n",
       " 'vibrantes',\n",
       " 'Também',\n",
       " 'é',\n",
       " 'extremamente',\n",
       " 'inteligente',\n",
       " ',',\n",
       " 'mas',\n",
       " 'simples',\n",
       " 'vai',\n",
       " 'direto',\n",
       " 'ao',\n",
       " 'ponto',\n",
       " 'e',\n",
       " 'eu',\n",
       " 'aprecio',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'dou',\n",
       " 'um',\n",
       " 'e',\n",
       " 'recomendo']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = dados()\n",
    "teste_tokens = teste.tokens(frase)\n",
    "stop = teste.remove_stopwords(teste_tokens, idioma)\n",
    "lemm = teste.stemmer(stop)\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c69e5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:24:30.044053Z",
     "start_time": "2022-08-31T01:24:29.723762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It used to be my thinking that movies required...</td>\n",
       "      <td>0</td>\n",
       "      <td>It used to be my thinking that movies required...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given that a lot of horror films are based on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Given that a lot of horror films are based on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went into this movie with very little in ter...</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into this movie with very little in ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picking this up along with the rest of the Mar...</td>\n",
       "      <td>0</td>\n",
       "      <td>Picking this up along with the rest of the Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was really surprised with this movie. Going ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I was really surprised with this movie  Going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Bo Derek's beauty and John Derek's revolutiona...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bo Derek s beauty and John Derek s revolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>What a terrible movie! The acting in this film...</td>\n",
       "      <td>0</td>\n",
       "      <td>What a terrible movie  The acting in this film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>A film about an interesting and sensitive peri...</td>\n",
       "      <td>0</td>\n",
       "      <td>A film about an interesting and sensitive peri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>I was never in the past interested in this pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>I was never in the past interested in this pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Movies like these do not need sequels. Part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Movies like these do not need sequels  Part of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     It used to be my thinking that movies required...      0   \n",
       "1     Given that a lot of horror films are based on ...      0   \n",
       "2     I went into this movie with very little in ter...      0   \n",
       "3     Picking this up along with the rest of the Mar...      0   \n",
       "4     I was really surprised with this movie. Going ...      1   \n",
       "...                                                 ...    ...   \n",
       "4995  Bo Derek's beauty and John Derek's revolutiona...      1   \n",
       "4996  What a terrible movie! The acting in this film...      0   \n",
       "4997  A film about an interesting and sensitive peri...      0   \n",
       "4998  I was never in the past interested in this pla...      1   \n",
       "4999  Movies like these do not need sequels. Part of...      0   \n",
       "\n",
       "                                         filtered_words  \n",
       "0     It used to be my thinking that movies required...  \n",
       "1     Given that a lot of horror films are based on ...  \n",
       "2     I went into this movie with very little in ter...  \n",
       "3     Picking this up along with the rest of the Mar...  \n",
       "4     I was really surprised with this movie  Going ...  \n",
       "...                                                 ...  \n",
       "4995  Bo Derek s beauty and John Derek s revolutiona...  \n",
       "4996  What a terrible movie  The acting in this film...  \n",
       "4997  A film about an interesting and sensitive peri...  \n",
       "4998  I was never in the past interested in this pla...  \n",
       "4999  Movies like these do not need sequels  Part of...  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = dados()\n",
    "pipeline = [\n",
    "    'caractere',\n",
    "    'digito',\n",
    "    'minusculo_lower',\n",
    "    'tokens',\n",
    "    'remove_stopwords',\n",
    "    'stemmer']\n",
    "\n",
    "movies_sample['filtered_words'] = movies_sample['text'].apply(preprocess.pipeline, methods=pipeline)\n",
    "movies_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14c43c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:01:55.342583Z",
     "start_time": "2022-08-31T01:01:55.332574Z"
    }
   },
   "outputs": [],
   "source": [
    "frase = 'Fui para ver este100 200 300 filme com cautela Uma comédia / / * #suicida Não parecia consistente Ter um irmão que tentou suicídio e ver a devastação que causou toda a nossa família Eu sei em primeira mão como pode ser esmagador lidar com esse problema. devo dizer Este filme lida com isso de uma maneira que permite ao espectador dentro de alguém que está sofrendo e simplesmente não sabe por que ou como pará-lo Embora o filme não seja perfeito, ele respeita o assunto e, mais importante, o torna acessível para as massas Eu sei que para a nossa família o humor tem nos ajudado a passar por muita dor E Max e Grace é exatamente o que prenuncia ser uma COMÉDIA suicida É engraçado E eu também senti que os personagens eram reais e vibrantes Também é extremamente inteligente, mas simples vai direto ao ponto e eu aprecio que eu dou um e recomendo '\n",
    "idioma = \"ingles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4adec260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:09:51.771206Z",
     "start_time": "2022-08-31T01:09:51.749186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wiltd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fui',\n",
       " 'par',\n",
       " 'ver',\n",
       " 'este100',\n",
       " '200',\n",
       " '300',\n",
       " 'film',\n",
       " 'com',\n",
       " 'cautel',\n",
       " 'uma',\n",
       " 'coméd',\n",
       " '/',\n",
       " '/',\n",
       " '*',\n",
       " '#',\n",
       " 'suic',\n",
       " 'não',\n",
       " 'parec',\n",
       " 'consist',\n",
       " 'ter',\n",
       " 'um',\n",
       " 'irm',\n",
       " 'que',\n",
       " 'tent',\n",
       " 'suicídi',\n",
       " 'e',\n",
       " 'ver',\n",
       " 'devast',\n",
       " 'que',\n",
       " 'caus',\n",
       " 'tod',\n",
       " 'noss',\n",
       " 'famíl',\n",
       " 'eu',\n",
       " 'sei',\n",
       " 'em',\n",
       " 'prim',\n",
       " 'mão',\n",
       " 'com',\n",
       " 'pod',\n",
       " 'ser',\n",
       " 'esmag',\n",
       " 'lid',\n",
       " 'com',\n",
       " 'ess',\n",
       " 'problem',\n",
       " '.',\n",
       " 'dev',\n",
       " 'diz',\n",
       " 'est',\n",
       " 'film',\n",
       " 'lid',\n",
       " 'com',\n",
       " 'iss',\n",
       " 'de',\n",
       " 'uma',\n",
       " 'man',\n",
       " 'que',\n",
       " 'permit',\n",
       " 'ao',\n",
       " 'espect',\n",
       " 'dentr',\n",
       " 'de',\n",
       " 'alguém',\n",
       " 'que',\n",
       " 'est',\n",
       " 'sofr',\n",
       " 'e',\n",
       " 'simples',\n",
       " 'não',\n",
       " 'sab',\n",
       " 'por',\n",
       " 'que',\n",
       " 'ou',\n",
       " 'com',\n",
       " 'pará-l',\n",
       " 'emb',\n",
       " 'film',\n",
       " 'não',\n",
       " 'sej',\n",
       " 'perfeit',\n",
       " ',',\n",
       " 'ele',\n",
       " 'respeit',\n",
       " 'assunt',\n",
       " 'e',\n",
       " ',',\n",
       " 'mais',\n",
       " 'import',\n",
       " ',',\n",
       " 'torn',\n",
       " 'acess',\n",
       " 'par',\n",
       " 'mass',\n",
       " 'eu',\n",
       " 'sei',\n",
       " 'que',\n",
       " 'par',\n",
       " 'noss',\n",
       " 'famíl',\n",
       " 'hum',\n",
       " 'tem',\n",
       " 'no',\n",
       " 'ajud',\n",
       " 'pass',\n",
       " 'por',\n",
       " 'muit',\n",
       " 'dor',\n",
       " 'e',\n",
       " 'max',\n",
       " 'e',\n",
       " 'grac',\n",
       " 'é',\n",
       " 'exat',\n",
       " 'que',\n",
       " 'prenunc',\n",
       " 'ser',\n",
       " 'uma',\n",
       " 'coméd',\n",
       " 'suic',\n",
       " 'é',\n",
       " 'engraç',\n",
       " 'e',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'sent',\n",
       " 'que',\n",
       " 'os',\n",
       " 'person',\n",
       " 'er',\n",
       " 'real',\n",
       " 'e',\n",
       " 'vibr',\n",
       " 'também',\n",
       " 'é',\n",
       " 'extrem',\n",
       " 'intelig',\n",
       " ',',\n",
       " 'mas',\n",
       " 'simpl',\n",
       " 'vai',\n",
       " 'diret',\n",
       " 'ao',\n",
       " 'pont',\n",
       " 'e',\n",
       " 'eu',\n",
       " 'apreci',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'dou',\n",
       " 'um',\n",
       " 'e',\n",
       " 'recom']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frase = movies_sample[\"text\"][0]\n",
    "teste = dados()\n",
    "teste_tokens = teste.tokens(frase)\n",
    "stop = teste.remove_stopwords(teste_tokens, idioma)\n",
    "stemme = teste.stemmer(stop)\n",
    "stemme\n",
    "#teste.pipeline(lemm, tratamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccaa1417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:07:31.734918Z",
     "start_time": "2022-08-31T01:07:31.726912Z"
    }
   },
   "outputs": [],
   "source": [
    "phrase = movies_sample[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc59b925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:07:36.786688Z",
     "start_time": "2022-08-31T01:07:36.780683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It used to be my thinking that movies required plots, or some other means of making you care at all about the story line or anything that is going on. This movie has showed me that you don't actually have to have anything like that.<br /><br />I could sum it up simply as that. But, IMDb wants me to have more lines. It was kind of pretty. not compelling in the slightest. The way the characters talk in the movie makes you think it should have taken place over a matter of days, but there is no passage of time and i'm pretty sure it all happens in an hour.<br /><br />If you are looking to entertain yourself, then buy a gallon of milk and see how fast you can drink it before throwing up. It would be a far better use of your time. Time that you will never get back. Jurassic Park 3 was pulled off better than this movie.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c10c625b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T01:08:21.737594Z",
     "start_time": "2022-08-31T01:08:21.716575Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mdados.pipeline\u001b[1;34m(self, text, methods)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m#print(text)\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtratamento\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m************\u001b[39m\u001b[38;5;124m'\u001b[39m, m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "preprocess.pipeline(phrase, methods=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa1f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
