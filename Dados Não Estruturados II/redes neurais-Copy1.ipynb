{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849d3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plot\n",
    "from random import randint\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c339b",
   "metadata": {},
   "source": [
    "#### Introdução a Redes Neurais\n",
    "\n",
    "* Algoritmo de aprendizagem de máquina inspirado no neurônio biológico, possuindo uma estrutura básica chamada neurônio\n",
    "\n",
    "1. Neurônio biológico\n",
    "\n",
    "![Title](../imgs/neuronio.jpg)\n",
    "\n",
    "2. Neurônio de uma rede neural (perceptron)\n",
    "\n",
    "* Estrutura com pesos para cada entrada\n",
    "* Objetivo de encontrar os melhores pesos para classificar um problema\n",
    "* Funciona apenas para problemas linearmente separáveis\n",
    "\n",
    "![Title](../imgs/perceptron.png)\n",
    "\n",
    "3. Para formar uma rede neural propriamente dita, tem-se um conjunto de neurônios\n",
    "* Múltiplos neurônios formam uma camada\n",
    "* Possibilidade de resolver problemas que não são linearmente separáveis\n",
    "![Title](../imgs/rn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk import pos_tag\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9df8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras as keras\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0476ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/cecilia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Instancia o PorterStemmer\n",
    "stemmer = PorterStemmer()                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becfca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../datasets/movies.csv', index_col=0)\n",
    "movies_sample = movies.sample(frac=0.1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e315b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(string):\n",
    "    ###\n",
    "    # Remove acentuações\n",
    "    string = unidecode(string)\n",
    "    ###\n",
    "    # Deixa apenas elementos alfanuméricos\n",
    "    string = re.sub(r\"[^a-zA-Z0-9]+\", ' ', string)\n",
    "    ###\n",
    "    # deixa todas as palavras minúsculas\n",
    "    string = string.lower()\n",
    "    ###\n",
    "    # tokenização\n",
    "    words = word_tokenize(string)\n",
    "    ###\n",
    "    # Remove Stopwords\n",
    "    filtered_words = []\n",
    "    for w in words:\n",
    "        if w not in stopwords:\n",
    "            filtered_words.append(w)\n",
    "    ###\n",
    "    # Aplica o Stemming\n",
    "    stem_words = []\n",
    "    for w in filtered_words:\n",
    "        s_words = stemmer.stem(w)\n",
    "        stem_words.append(s_words)\n",
    "    ###\n",
    "    # Retorna a lista de palavras pré-processadas\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfaf21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o preprocessing nas críticas de filmes\n",
    "movies_sample[\"filtered_words\"] = movies_sample['text'].apply(lambda x: preprocessing(x))\n",
    "\n",
    "# Normalmente, depois do processamento juntamos as palavras novamente em uma só string\n",
    "movies_sample['join_words'] = movies_sample['filtered_words'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd7d8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados em X e Y\n",
    "X = movies_sample['join_words']\n",
    "y = movies_sample['label']\n",
    "\n",
    "# Carrega o train_test_split para separar a base em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa os dados em treino e teste\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                     y,\n",
    "                                                     test_size = 0.3,\n",
    "                                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f99e1",
   "metadata": {},
   "source": [
    "### Usando Contadores de Frequencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c86577",
   "metadata": {},
   "source": [
    "### Usando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627dd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
