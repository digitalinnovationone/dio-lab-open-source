{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização bayesiana\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Otimização bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na parte prática da aula de hoje, usaremos a biblioteca [hyperopt](http://hyperopt.github.io/hyperopt/)\n",
    "\n",
    "Para instalá-la, o de sempre:\n",
    "\n",
    "`pip install hyperopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T17:51:27.177016Z",
     "start_time": "2022-06-27T17:51:24.753278Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "Desde que conhecemos os primeiros estimadores utilizados para a construção de modelos, uma preocupação adicional nos acompanhou: o ajuste de valores dos hiperparâmetros.\n",
    "\n",
    "Quase todos os estimadores que conhecemos têm um ou mais **hiperparâmetros** associados.\n",
    "\n",
    "Como vimos, os hiperparâmetros influenciam o comportamento do modelo (e, portanto, são muito importantes), mas eles não são determinados a partir dos dados! É nosso dever, como cientistas de dados, fornecer valores adequados para os hiperparâmetros.\n",
    "\n",
    "No começo de nossa jornada, nós utilizávamos os valores default para os hiperparâmetros, ou então, mudávamos manualmente alguns valores, para sensibilizar a influência dos hiperparâmetros no modelo final.\n",
    "\n",
    "Mas logo percebemos que essa não era a melhor abordagem --- precisávamos de um método mais sistemàtico para a busca de bons valores para os hiperparâmetros!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "Para este fim, introduzimos inicialmente o **grid search**, que **testa exaustivamente** combinações explícitas de valores de hiperparâmetros.\n",
    "\n",
    "Apesar de simples e direta, esta é uma abordagem computacionalmente muito custosa (sentimos isso na pele, ao rodar rotinas de grid search que demoram horas, ou até mesmo dias!). \n",
    "\n",
    "De fato, esta é uma abordagem de força bruta que, aliás, não nos dá garantia nenhuma: é perfeitamente possível que nenhuma das combinações que estabelecemos seja boa boa! Oras, há muitos casos em que o **espaço de hiperparâmetros** é infinito (basta considerar um hiperparâmetro dado por um float que não é limitado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "Para endereçar este problema, introduzimos então o **random search**.\n",
    "\n",
    "Neste caso, ao invés de disponibilizarmos valores específicos de hiperparâmetros a serem combinados, disponibilizamos **intervalos** ou explicitamente **distribuições de probabilidade** sobre o espaço de parâmetros de cada hiperparâmetro, e **amostramos valores aleatórios** destas distribuições para gerar as combinações.\n",
    "\n",
    "Com essa abordagem estocástica, há a possibilidade de encontrarmos boas combinações, que não estariam inclusas nos valores explícitos que passamos para o grid search.\n",
    "\n",
    "Por outro lado, com o random search também não temos garantia alguma que as melhores combinações serão encontradas, sobretudo porque **todas as combinações são amostradas de maneira aleatória**. Ou seja, todas as combinações são amostradas **sem considerar** a performance das combinações anteriores. Com esta metodologia, fica difícil garantirmos que efetivamente encontraremos boas combinações..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodologia de grid search (à esquerda) vs random search (à direita):\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Minrui-Zheng/publication/328252103/figure/fig4/AS:766093471801344@1559662325592/Distribution-of-sampled-hyperparameters-a-grid-search-b-random-search.png width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "Então, podemos nos perguntar: qual seria o próximo passo? Existiria um método ainda mais eficiente e \"educado\" para fazer a otimização de hiperparâmetros?\n",
    "\n",
    "A resposta é: sim! Hoje, conheceremos o método de **otimização Bayesiana**, aplicada à otimização de hiperparâmetros!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "_________\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Otimização Bayesiana\n",
    "\n",
    "O objetivo da otimização baeysiana é o mesmo que tínhamos com o grid e random search: **determinar os valores adequados para um conjunto de hiperparâmetros**, de modo que a combinação de valores **proporcione os melhores valores para uma métrica de avaliação calculada em dados de validação**.\n",
    "\n",
    "O que muda com a otimização baeysiana é a forma como isso será feito.\n",
    "\n",
    "Já descrevemos os problemas que ambos grid e random search têm. Sobretudo, o fato das combinações de valores dos hiperparâmetros serem independentes entre si, sem levar em consideração combinações anteriores, que poderiam ser boas.\n",
    "\n",
    ">Pra entender isso melhor, imagine o cenário em que queremos otimizar 3 hiperparâmetros.\n",
    "<br><br>\n",
    ">Pode ser que, em uma combinação, encontremos bons valores para 2 dos 3 hiperparâmetros; ja, na próxima, como os 3 valores serão novos, pode ser que os 3 sejam ruins. Não seria interessante de conseguíssemos manter a informação sobre os valores bons que encontramos?\n",
    "\n",
    "Esse é o espírito da otimização baeysiana!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra entender isso intuitivamente, considere a figura a seguir (suponha que o \"score\" é um erro, então, quanto menor, melhor):\n",
    "\n",
    "<img src=https://miro.medium.com/max/1120/1*MiNXGrkk5BbjfkNAXZQSNA.png width=400>\n",
    "\n",
    "Pergunta: onde você concentraria a busca por valores do hiperparâmetro `n_estimators`?\n",
    "\n",
    "Olhando pro gráfico, existe claramente uma região no espaço do hiperparâmetro `n_estimators` que é melhor: menos de 200 árvores.\n",
    "\n",
    "**Uma vez que temos este conhecimento**, realmente não faz sentido algum que os próximos valores que vamos testar sejam maiores que 200, não é mesmo?\n",
    "\n",
    "Esse é o espírito da otimização bayesiana: **utilizamos a informação que temos quanto ao score alcançado com valores iniciais de hiperparâmetros para guiar a escolha dos próximos valores!**\n",
    "\n",
    "E aqui já fica claro o porquê do método receber o título \"bayesiano\": de fato, estamos nos utilizando da \"filosofia\" bayesiana de ajuste de estratégia conforme agregamos novas informações! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">E é por isso que a otimização bayesiana é tão mais eficiente que as estratégias anteriores: gastamos um pouco mais de energia para propor combinações de hiperparâmetros **levando em consideração** as combinações passadas e suas respectivas perfomances.\n",
    "<br><br>\n",
    "Com isso, podemos focar apenas em testar **combinações promissoras**, e não precisamos gastar energia em procurar por combinações que sabemos não ser tão boas.\n",
    "\n",
    "Faz sentido, não é mesmo?\n",
    "\n",
    "Agora, precisamos apenas entender **como** é possível implementar isso. Vamos estab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Função objetivo\n",
    "\n",
    "É razoável assumirmos que existe uma função que relaciona a métrica de performance (score) que temos interesse de otimizar e os hiperparâmetros, não é mesmo?\n",
    "\n",
    "Sabendo que as métricas de performance essencialmente comparam os targets preditos com os targets reais, e sabendo que os targets preditos (pela hipótese) são influenciados pelos hiperparâmetros, é bem natural que assumamos que esta função existe.\n",
    "\n",
    "Agora, o ponto é que pode ser extremamente difícil escrever esta função explicitamente. Como nosso objetivo será encontrar valores que **otimizam** a função, costumamos chamá-la de **função objetivo**. \n",
    "\n",
    "Mas, veja, queremos otimizar uma função onjetivo **sem nem saber qual é sua dependência funcional com os hiperparâmetros**. Problemas deste tipo são chamados de **otimização de caixa-preta**, e existem várias técnicas para abordá-los. Recomendo [este material](https://www.lix.polytechnique.fr/~dambrosio/blackbox_material/Cassioli_1.pdf) aos interessados.\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Abraham-Duarte/publication/236164556/figure/fig1/AS:393408515461120@1470807307227/Schematic-representation-of-the-black-box-optimization-framework.png width=500>\n",
    "\n",
    "Quando formos pra prática, construiremos a função objetivo implicitamente, como o resultado retornado por uma **métrica de avaliação** dado o treinamento de um modelo. \n",
    "\n",
    "Na prática, isso nos será suficiente, pois bastará que tomemos **alguns pontos** desta função, para seguir com sua otimização, isso graças à introdução do surrogate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Surrogate model\n",
    "\n",
    "Na prática, iremos apenas **avaliar alguns pontos da função objetivo** e construir um **modelo probabilístico dela** com base nestes pontos, que serão tratados como **amostras**.\n",
    "\n",
    "Este modelo probabílistico é conhecido como **surrogate model (modelo substituto ou emulador)**, pois ele emula probabilisticamente o que seria a função real, sem a necessidade dela ser reconstruída explicitamente. E o melhor, dado que o modelo surrogate é bem mais simples que a função objetivo, será muito mais fácil otimizá-lo do que a função objetivo em si!\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Seung-Seop-Jin-2/publication/297605027/figure/fig1/AS:339392045568000@1457928777016/Concept-of-sequential-surrogate-modelling.png width=600>\n",
    "\n",
    "O ponto é que nosso modelo surrogate será atualizado **de maneira bayesiana**, isto é, levando em consideração scores anteriores, para sugerir as próximas combinações de hiperparâmetros de maneira mais principada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operacionalmente, seguiremos o seguinte passo-a-passo:\n",
    "\n",
    "- Construiremos um modelo probabilístico surrogate para a função objetivo;\n",
    "- Otimizaremos o modelo surrogate, encontrando bons valores para os hiperparâmetros nesta função;\n",
    "- Utilizamos estes valores encontrados e damos de input para a função objetivo real, e amostramos um novo ponto;\n",
    "- Atualizamos o modelo surrogate, incorporando o novo ponto amostrado;\n",
    "- Repetimos os últimos 3 passos, até atingirmos o critério de parada (em geral, um número pré-definido de passos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há muitas formas possíveis para o modelo surrogate. Um método muito interessante é o que utiliza processos gaussianos. Sugiro muito a leitura [deste post interativo](https://distill.pub/2019/visual-exploration-gaussian-processes/) para conhecer um pouco mais sobre este método; e [este post](https://towardsdatascience.com/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0) para uma intuição quanto a sua aplicação como modelo surrogate da otimização bayesiana.\n",
    "\n",
    "Na nossa implementação prática, utilizaremos o método conhecido como **Tree-structured Parzen Estimator** (TPE) para a construção do modelo surrogate.\n",
    "\n",
    "Não nos preocuparemos com a matemática por trás do método. (Aos interessados, sugiro a leitura [deste artigo](https://www.diva-portal.org/smash/get/diva2:1223709/FULLTEXT01.pdf), que compara diferentes modelos surrogates e técnicas de otimização de hiperparâmetros, no contexto de redes neurais, embora as ideias sejam válidas no geral)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta sabermos o seguinte: o TPE precisa de um **threshold de score**:\n",
    "\n",
    "<img src=https://miro.medium.com/max/1120/1*H5pyf3G115WGJwPpg65yaQ.png width=400>\n",
    "\n",
    "Com base neste score, o método gera distribuições de probabilidade a priori, para ambos os valores de hiperparâmetros que estão acima e abaixo do threshold.\n",
    "\n",
    "Uma vez em posse destas distribuições, o método se utiliza então de um **critério de escolha** que favorece valores dos hiperparâmetros que estão do lado do threshold que nos interessa (no caso deste exemplo, abaixo do threshold), e estes valores são propostos como os próximos hiperparâmetros a serem escolhidos.\n",
    "\n",
    "E é assim que o TPE consegue \"focar nas regiões promissoras\" do espaço de hiperparâmetros. Muito legal, não é mesmo?\n",
    "\n",
    "Mas ainda resta uma pergunta: qual é exatamente este critério de escolha das regiões? **Como**, a cada iteração, os próximos valores de hiperparâmetros são propostos, com o objetivo de minimizar a função objetivo?\n",
    "\n",
    "Isto é feito de acordo com a chamada **função de seleção**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Função de seleção\n",
    "\n",
    "O objetivo da função de seleção é muito simples: **determinar os valores dos hiperparâmetros que são escolhidos do modelo surrogate** a cada passo.\n",
    "\n",
    "Há vários critérios possíveis, mas o mais comum é conhecido como **Expected Improvement** (melhoria esperada), e ela é uma função do modelo surrogate. Seu uso é bem direto: **propomos novos valores de hiperparâmetros de modo que o expected improvement seja maximizado**. \n",
    "\n",
    "Podemos omitir aqui os detalhes matemáticos, o importante é lembrarmos que é o papel da função de seleção estabelecer o critério segundo o qual o modelo surrogate irá proporcionar os valores de hiperparâmetros a cada iteração.\n",
    "\n",
    "E, com isso, conseguimos, a cada iteração, propor candidatos a valores de hiperparâmetros que melhoram o modelo surrogate. O registro destes valores é muito importante, para que o teorema de Bayes entre em ação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Histórico de registros\n",
    "\n",
    "O histórico de registros, que é uma tupla com **(valores de hiperparâmetros, respectivo score)** é muitíssimo importante para que seja possível a construção de um modelo surrogate que, a cada passo, melhora a descrição probabilística da função objetivo.\n",
    "\n",
    "Isso é importante pois, quão melhor for nossa descrição da função objetivo, teremos que o passo disponibilizado pelo expected improvement irá proporcionar hiperparâmetros mais próximos do ótimo da função objetivo. \n",
    "\n",
    "E é aqui que o teorema de Bayes entra em ação: a partir de novas evidências (amostras do surrogate), atualizamos a nossa descrição da funcção objetivo com cada vez mais detalhes, e, assim, ela fica mais fácil de ser otimizada, sem precisar ser explicitamente construída!\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*RQ-pAwQ88yC904QppChGPQ.png width=500>\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*bSLAe1LCj3mMKfaZsQWCrw.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já conhecemos todos os ingredientes importantes, podemos dizer enunciar o passo-a-passo da otimização bayesiana:\n",
    "\n",
    "- Primeiro definimos um espaço de busca para cada um dos hiperparâmetros, impondo uma distribuição de probabilidade sobre o espaço;\n",
    "- Construímos implicitamente a função objetivo, que tem como inputs os hiperparâmetros, e como output o score a ser otimizado (que será a métrica de avaliação de interesse);\n",
    "- Construímos o modelo surrogate probabilístico da função objetivo;\n",
    "- Construímos a função de seleção, que irá determinar os próximos valores para os hiperparâmetros a serem escolhidos do modelo surrogate;\n",
    "- Atualizamos um histórico de valores de hiperparâmetros e respectivo score, que é utilizado pelo algoritmo para a atualização do modelo surrogate;\n",
    "- Repetimos o processo até o critério de parada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "\n",
    "E é isso!\n",
    "\n",
    "Para os interessados em maiores detalhes matemáticos, recomendo fortemente [este artigo](http://proceedings.mlr.press/v28/bergstra13.pdf), e [este também](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf), que reporta resultados incríveis a favor do uso de otimização bayesiana como alternativa aos métodos tradicionais de otimização de hiperparâmetros.\n",
    "\n",
    "Agora, vamos ver o método funcionando na prática!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir um modelo com os hiperparâmetros default (mas `learning_rate=0.1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada mal. Vamos ver se conseguimos melhorar com o Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T20:02:39.023720Z",
     "start_time": "2022-03-11T20:02:39.000730Z"
    }
   },
   "source": [
    "Resultado legal, melhoramos um pouco o f1.\n",
    "\n",
    "Mas será que não dá pra melhorar ainda mais? Vamos pra otimização Bayesiana!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install -c conda-forge hyperopt  \n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T17:57:05.495674Z",
     "start_time": "2022-06-27T17:56:58.268859Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin, Trials, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, definimos o espaço de parâmetros. [Veja aqui](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/) outras opções!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, definimos a função objetivo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, instanciamos a classe [Trials()](http://hyperopt.github.io/hyperopt/getting-started/minimizing_functions/#the-trials-object), que é a interface que nos permitirá realizar a otimização bayesiana, e que guarada o histórico, como veremos.\n",
    "\n",
    "Note que também passamos o TPE como algoritmo para o modelo surrogate, o que é dado pelo `tpe.suggest`.\n",
    "\n",
    "Indicamos também o número máximo de passos que queremos, com o `max_evals`.\n",
    "\n",
    "A otimização em si é realizada com a chamada da função `fmin()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar os hiperparâmetros para a o espaço correto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brincando com a seed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
